{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model hyper params\n",
    "# load some test image\n",
    "# load some interactive window & plot it\n",
    "# do it for changing one codeword at a fixed position across codebook\n",
    "# etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def update_yaml(yaml_file_path = \"/home/novakovm/iris/MILOS/\",\n",
    "                yaml_file_name = \"toy_shapes_config\",\n",
    "                key = \"NUM_WORKERS\", \n",
    "                value = 5,\n",
    "                source = \"training_hyperparams\"):\n",
    "    # make a new yaml config file from human readable version of that same file\n",
    "    yaml_full_src_path = yaml_file_path + yaml_file_name+ \"_human_readable\" +\".yaml\"\n",
    "    yaml_full_dsc_path = yaml_file_path + yaml_file_name +\".yaml\"\n",
    "    data_dict = yaml.load(open(yaml_full_src_path, 'r'), Loader=yaml.FullLoader)\n",
    "    with open(yaml_full_dsc_path, 'w') as yaml_file:\n",
    "        yaml_file.write( yaml.dump(data_dict, default_flow_style=False))\n",
    "    \n",
    "    # update the newly created non-human readable file\n",
    "    data_dict = yaml.load(open(yaml_full_dsc_path, 'r'), Loader=yaml.FullLoader)\n",
    "    # pick the desired source list in the data dict. yaml file\n",
    "    data_source_list = data_dict[source]\n",
    "    # find the index in the list where the desired key is\n",
    "    data_source_list_key_index = [idx for idx, data_key in enumerate(data_source_list) if key in data_key][0]\n",
    "    # update step\n",
    "    data_source_list[data_source_list_key_index][key] = value\n",
    "    # save the change\n",
    "    with open(yaml_full_dsc_path, 'w') as yaml_file:\n",
    "        yaml_file.write( yaml.dump(data_dict, default_flow_style=False))\n",
    "update_yaml(yaml_file_path = \"/home/novakovm/iris/MILOS/\",\n",
    "            yaml_file_name = \"toy_shapes_config\",\n",
    "            key = \"NUM_WORKERS\", \n",
    "            value = 5)\n",
    "update_yaml(yaml_file_path = \"/home/novakovm/iris/MILOS/\",\n",
    "            yaml_file_name = \"crafter_config\",\n",
    "            key = \"NUM_WORKERS\", \n",
    "            value = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/novakovm/miniconda3/envs/iris_mn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-20 09:37:40.339510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 09:37:40.807260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 09:37:40.807307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 09:37:40.807311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from run_pipeline import run\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "clear_output(wait=True)\n",
    "#clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_one_token(trainers, dataset_name = \"toy_dataset\", dataset_type = \"test\"):\n",
    "    M = trainers[dataset_name].model.VQ.M\n",
    "    K = trainers[dataset_name].model.VQ.K\n",
    "\n",
    "    image_batch, image_id_batch = next(iter(trainers[dataset_name].loaders[dataset_type]))\n",
    "    image_batch,image_id_batch = image_batch.to(trainers[dataset_name].device), image_id_batch.to(trainers[dataset_name].device)\n",
    "\n",
    "    trainers[dataset_name].model.VQ.output_whole_quantization_process = True\n",
    "    e_and_q_latent_loss, Zq, e_latent_loss, q_latent_loss, estimate_codebook_words, encoding_indices, estimate_codebook_words_freq, estimate_codebook_words_prob, inputs, D  = \\\n",
    "        trainers[dataset_name].model.VQ(trainers[dataset_name].model.encoder(image_batch))\n",
    "    trainers[dataset_name].model.VQ.output_whole_quantization_process = False\n",
    "    \n",
    "    changed_token_map_position_range_step = 1\n",
    "    changed_token_map_position_range = np.arange(0,K,changed_token_map_position_range_step)\n",
    "    for changed_token_map_position_row in np.arange(M+1):\n",
    "        for changed_token_map_position_column in np.arange(M+1):\n",
    "            \n",
    "            digit_size = len(str(len(trainers[dataset_name].loaders[dataset_type].dataset)))\n",
    "            \n",
    "            for index_, changed_token_map_position_value in enumerate(changed_token_map_position_range):\n",
    "                new_encoding_indices = encoding_indices.clone().detach().view(M+1,M+1)\n",
    "                new_encoding_indices[changed_token_map_position_row, changed_token_map_position_column] = changed_token_map_position_value\n",
    "                new_encoding_indices = new_encoding_indices.view(-1,1)\n",
    "                trainers[dataset_name].original_reconstructed_changed_reconstucted_tokens_changed_tokens(  image_batch,# one image, it is the tensor of shape = (1,C,H,W)\n",
    "                                                                                                            image_id_batch,#id\n",
    "                                                                                                            new_encoding_indices, \n",
    "                                                                                                            index_,\n",
    "                                                                                                            dataset_str = dataset_type,\n",
    "                                                                                                            create_plot_for_every_image_in_dataset = False, \n",
    "                                                                                                            jupyter_show_images = False)\n",
    "            frames_per_second = 5#10#5#10#1\n",
    "            format_list = ['mp4', 'gif']\n",
    "            for format_ in format_list:\n",
    "                with imageio.get_writer(trainers[dataset_name].visualize_tokens_path + f\"_{str(changed_token_map_position_row).zfill(1)}_x_{str(changed_token_map_position_column).zfill(1)}_token_changed_{format_}.{format_}\", mode='I', fps = frames_per_second) as writer:\n",
    "                    for index_, changed_token_map_position_value in enumerate(changed_token_map_position_range):\n",
    "                        filename = trainers[dataset_name].all_images_full_path + f\"{str(index_).zfill(digit_size)}_custom_image.png\"\n",
    "                        image = imageio.imread(filename)\n",
    "                        writer.append_data(image)\n",
    "                    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = {\"toy_dataset\" : \"/home/novakovm/iris/MILOS/toy_shapes_config.yaml\",\n",
    "                \"crafter_dataset\" : \"/home/novakovm/iris/MILOS/crafter_config.yaml\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainers['toy_dataset'] = run(config_paths[\"toy_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Params in thousands: 1765\n",
      "\n",
      "Total Memory =  25.43 GB.\n",
      "Reserved Memory =  0.00 GB.\n",
      "Allocated inside Reserved Memory =  0.00 GB.\n",
      "Free inside Reserved Memory =  0.00 GB.\n",
      "\n",
      "Global Free memory on the cuda:0 =  22.58 GB.\n",
      "Total GPU Memory occupied on the cuda:0 =  25.43 GB.\n",
      "\n",
      "Inverse of training data variance term is equal to =  3.9\n",
      "Testing Started\n",
      "Average test total loss =  6742 e-6\n",
      "Average test total reconstruction loss =  4287 e-6 (64 %)\n",
      "Average test total commitment loss =  491 e-6 (7 %)\n",
      "Average test total VQ loss =  1964 e-6 (29 %)\n",
      "Testing Ended\n"
     ]
    }
   ],
   "source": [
    "trainers['crafter_dataset'] = run(config_paths[\"crafter_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2192295/4248046032.py:37: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filename)\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "change_one_token(trainers, dataset_name = \"crafter_dataset\", dataset_type = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris_mn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14524dedb1f240cfa87933405c6db7624e3e5d5d03a9d9b3f38011393b6d44e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
