{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/novakovm/miniconda3/envs/iris_mn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/novakovm/iris/MILOS/models.py:509: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f'Unknown config parameter name = {param_name}.')\n",
      "/home/novakovm/iris/MILOS/models.py:628: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f'Unknown config parameter name = {param_name}.')\n",
      "/home/novakovm/iris/MILOS/models.py:978: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f\"There are no optimizers called {self.optimizer_settings['optimization_algorithm']}.\")\n",
      "/home/novakovm/iris/MILOS/models.py:1433: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.loaders['test'].batch_size == 1, f\"Mini-batch size of the test set should be 1, because of visualization and plotting later on in the code.\")\n",
      "/home/novakovm/iris/MILOS/models.py:2202: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(dataset_str in ['train', 'val', 'test'], f\"The dataset can only be train, val or test and current dataset is {dataset_str}\")\n",
      "/home/novakovm/iris/MILOS/models.py:2276: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.loaders[dataset_str].batch_size == 1, f\"Mini-batch size of the test set should be 1, because of visualization and plotting later on in the code.\")\n",
      "2023-01-21 21:50:37.810923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 21:50:38.276275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-21 21:50:38.276319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-21 21:50:38.276323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from run_pipeline import run\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import yaml\n",
    "import time\n",
    "from helper_functions import update_yaml, change_one_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Params in thousands: 1731\n",
      "\n",
      "Total Memory =  25.43 GB.\n",
      "Reserved Memory =  0.00 GB.\n",
      "Allocated inside Reserved Memory =  0.00 GB.\n",
      "Free inside Reserved Memory =  0.00 GB.\n",
      "\n",
      "Global Free memory on the cuda:0 =  24.52 GB.\n",
      "Total GPU Memory occupied on the cuda:0 =  25.43 GB.\n",
      "\n",
      "Inverse of training data variance term is equal to =  7.9\n",
      "Testing Started\n",
      "Average test total loss =  34464 e-6\n",
      "Average test total reconstruction loss =  23912 e-6 (69 %)\n",
      "Average test total commitment loss =  2110 e-6 (6 %)\n",
      "Average test total VQ loss =  8442 e-6 (24 %)\n",
      "Testing Ended\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (3000, 800) to (3008, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "/home/novakovm/iris/MILOS/helper_functions.py:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f\"There is no {hyperparam_name} at the config file at = {config_file_path}.\")\n",
      "/home/novakovm/iris/MILOS/helper_functions.py:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f\"There is no {hyperparam_name} at the config file at = {config_file_path}.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m image_id_in_dataset \u001b[39m=\u001b[39m trainers[dataset_name]\u001b[39m.\u001b[39mworst_imgs_ids[\u001b[39m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m image_index_in_dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(trainers[dataset_name]\u001b[39m.\u001b[39mloaders[dataset_type]\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mimage_ids \u001b[39m==\u001b[39m image_id_in_dataset)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m change_one_token(trainers, dataset_name, dataset_type, image_index_in_dataset)\n\u001b[1;32m     55\u001b[0m \u001b[39m# crafter\u001b[39;00m\n\u001b[1;32m     56\u001b[0m dataset_name, dataset_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcrafter_dataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/iris/MILOS/helper_functions.py:306\u001b[0m, in \u001b[0;36mchange_one_token\u001b[0;34m(trainers, dataset_name, dataset_type, image_index_in_dataset)\u001b[0m\n\u001b[1;32m    304\u001b[0m     filename \u001b[39m=\u001b[39m trainers[dataset_name]\u001b[39m.\u001b[39mall_images_full_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(index_)\u001b[39m.\u001b[39mzfill(digit_size)\u001b[39m}\u001b[39;00m\u001b[39m_custom_image.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     image \u001b[39m=\u001b[39m imageio\u001b[39m.\u001b[39mimread(filename)\n\u001b[0;32m--> 306\u001b[0m     writer\u001b[39m.\u001b[39;49mappend_data(image)\n\u001b[1;32m    307\u001b[0m writer\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/iris_mn/lib/python3.9/site-packages/imageio/core/format.py:589\u001b[0m, in \u001b[0;36mFormat.Writer.append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    587\u001b[0m im \u001b[39m=\u001b[39m asarray(im)\n\u001b[1;32m    588\u001b[0m \u001b[39m# Call\u001b[39;00m\n\u001b[0;32m--> 589\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append_data(im, total_meta)\n",
      "File \u001b[0;32m~/miniconda3/envs/iris_mn/lib/python3.9/site-packages/imageio/plugins/pillowmulti.py:84\u001b[0m, in \u001b[0;36mGIFFormat.Writer._append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m     82\u001b[0m     duration \u001b[39m=\u001b[39m duration[\u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(duration) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_writer\u001b[39m.\u001b[39m_count)]\n\u001b[1;32m     83\u001b[0m dispose \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispose\n\u001b[0;32m---> 84\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_writer\u001b[39m.\u001b[39;49madd_image(im, duration, dispose)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/iris_mn/lib/python3.9/site-packages/imageio/plugins/pillowmulti.py:128\u001b[0m, in \u001b[0;36mGifWriter.add_image\u001b[0;34m(self, im, duration, dispose)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt_subrectangle:\n\u001b[1;32m    127\u001b[0m     im_rect, rect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetSubRectangle(im)\n\u001b[0;32m--> 128\u001b[0m im_pil \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconverToPIL(im_rect, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt_quantizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt_palette_size)\n\u001b[1;32m    130\u001b[0m \u001b[39m# Get pallette - apparently, this is the 3d element of the header\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# (but it has not always been). Best we've got. Its not the same\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# as im_pil.palette.tobytes().\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGifImagePlugin\u001b[39;00m \u001b[39mimport\u001b[39;00m getheader\n",
      "File \u001b[0;32m~/miniconda3/envs/iris_mn/lib/python3.9/site-packages/imageio/plugins/pillowmulti.py:329\u001b[0m, in \u001b[0;36mGifWriter.converToPIL\u001b[0;34m(self, im, quantizer, palette_size)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m         im_pil \u001b[39m=\u001b[39m im_pil\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m     im_pil \u001b[39m=\u001b[39m im_pil\u001b[39m.\u001b[39;49mquantize(colors\u001b[39m=\u001b[39;49mpalette_size, method\u001b[39m=\u001b[39;49mquantizer)\n\u001b[1;32m    330\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid value for quantizer: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m quantizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/iris_mn/lib/python3.9/site-packages/PIL/Image.py:1167\u001b[0m, in \u001b[0;36mImage.quantize\u001b[0;34m(self, colors, method, kmeans, palette, dither)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     new_im\u001b[39m.\u001b[39mpalette \u001b[39m=\u001b[39m palette\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m new_im\n\u001b[0;32m-> 1167\u001b[0m im \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mquantize(colors, method, kmeans))\n\u001b[1;32m   1169\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImagePalette\n\u001b[1;32m   1171\u001b[0m mode \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mim\u001b[39m.\u001b[39mgetpalettemode()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "config_folder_names = { \"toy_dataset\" : \"/home/novakovm/iris/MILOS/\",\n",
    "                        \"crafter_dataset\" : \"/home/novakovm/iris/MILOS/\"}\n",
    "\n",
    "config_file_names = {   \"toy_dataset\" : \"toy_shapes_config\",\n",
    "                        \"crafter_dataset\" : \"crafter_config\"}\n",
    "\n",
    "config_full_file_paths = {}\n",
    "for dataset_name in config_file_names:\n",
    "    config_full_file_paths[dataset_name] = config_folder_names[dataset_name] + \\\n",
    "                                           config_file_names[dataset_name] + \".yaml\"\n",
    "\n",
    "\n",
    "K_BIT_MIN, K_BIT_MAX = 3,8\n",
    "D_array =np.array([64, 32, 16, 8])\n",
    "M_array = np.array([7, 3, 1]) #M_array = -np.sort(-M_array)\n",
    "K_array = 2** np.arange(K_BIT_MIN, K_BIT_MAX+1)\n",
    "K_array = -np.sort(-K_array)\n",
    "\n",
    "trainers = {}\n",
    "custom_logger= \"/home/novakovm/iris/MILOS/CUSTOM_LOGGER.txt\"\n",
    "\n",
    "# init values for run_ids\n",
    "run_id = { \"toy_dataset\" : 101,\n",
    "        \"crafter_dataset\" : 501}\n",
    "\n",
    "\"\"\"\n",
    "Delimiter in log_all.txt-like files for this simulation\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# config setup\n",
    "for dataset_name in config_file_names:\n",
    "    update_yaml(yaml_folder_name = config_folder_names[dataset_name],\n",
    "                yaml_file_name = config_file_names[dataset_name],\n",
    "                key = None, \n",
    "                value = None)\n",
    "    \n",
    "    \n",
    "trainers = {}\n",
    "\n",
    "# toy dataset\n",
    "dataset_name, dataset_type = \"toy_dataset\", \"test\"\n",
    "trainers[dataset_name] = run(config_full_file_paths[dataset_name])\n",
    "\n",
    "image_id_in_dataset = trainers[dataset_name].worst_imgs_ids[0]\n",
    "image_index_in_dataset = np.where(trainers[dataset_name].loaders[dataset_type].dataset.image_ids == image_id_in_dataset)[0][0]\n",
    "\n",
    "change_one_token(trainers, dataset_name, dataset_type, image_index_in_dataset)\n",
    "\n",
    "\n",
    "# crafter\n",
    "dataset_name, dataset_type = \"crafter_dataset\", \"test\"\n",
    "trainers[dataset_name] = run(config_full_file_paths[dataset_name])\n",
    "\n",
    "image_id_in_dataset = trainers[dataset_name].worst_imgs_ids[0]\n",
    "image_index_in_dataset = np.where(trainers[dataset_name].loaders[dataset_type].dataset.image_ids == image_id_in_dataset)[0][0]\n",
    "\n",
    "change_one_token(trainers, dataset_name, dataset_type, image_index_in_dataset = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_id_in_dataset = trainers[dataset_name].worst_imgs_ids[0]\n",
    "# image_index_in_dataset = np.where(trainers[dataset_name].loaders[dataset_type].dataset.image_ids == image_id_in_dataset)[0]\n",
    "# image_index_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = trainers[dataset_name].loaders[dataset_type]\n",
    "# loader_dataset = loader.dataset\n",
    "# #loader_dataset\n",
    "# loader_dataset.image_ids[image_index_in_dataset[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name, dataset_type = \"toy_dataset\", \"test\"\n",
    "# image_id_in_dataset = trainers[dataset_name].worst_imgs_ids[0]\n",
    "# image_index_in_dataset = np.where(trainers[dataset_name].loaders[dataset_type].dataset.image_ids == image_id_in_dataset)[0][0]\n",
    "# image_index_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = trainers[dataset_name].loaders[dataset_type]\n",
    "# loader_dataset = loader.dataset\n",
    "# image_batch,image_id_batch = loader_dataset[image_index_in_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch.shape#,image_id_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris_mn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14524dedb1f240cfa87933405c6db7624e3e5d5d03a9d9b3f38011393b6d44e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
